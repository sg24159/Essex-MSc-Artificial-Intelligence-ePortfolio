---
title: "03 Discussion 1: Summary: The importance of Human-Machine Interfaces"
category: Machine Learning
---

Natali Nikolic expanded on the ethical side of the situation, in particular, citing a report by Herkert, Borenstein and Miller (2020) who go into great detail about the many ways that Boeing as an organization failed to uphold engineering ethics. They bring up four key decisions that led to the failure: repositioning the engines, masking the resulting instability with MCAS, using only one sensor, and not training pilots on the changes. Any one of these is a point where engineering or management could have avoided the catastrophe.

Herkert, Borenstein and Miller (2020) speculate that engineers need to be reminded about their ethical duties to public good and public safety, they suggest that corporations should have stronger internal ethics programs. In my opinion, this does not go far enough, any program that Boeing can implement, they can also ignore in the future.

Pëllumb Dalipi emphasizes the usefulness of interpretability and audits. In my opinion, interpretability is not a contributing factor, the MCAS model behaved as designed, it is only once the outside components are added that the system as a whole failed. This is where some form of auditing could help, preferably from an internal quality department.

Assuring that a system functions as intended is traditionally done with test cases. These test cases are intended to reproduce the worst case scenarios and make sure the system functions correctly. While interpretability helps in determining which inputs may lead to unintended behaviour, it is still difficult to expect engineers to predict every possible combination of inputs that may lead to a failure (Vanderlinde, Robinson and Mashford, 2022).

There is a second way to view interpretability with respect to this disaster. It is not just the engineers who must understand their product, but also the users (Ahmed, Jeon and Piccialli, 2022). Pilots were not adequately trained on the existence of the MCAS system, and their attempts to regain control from a system they did not understand worsened the situation (Laeequddin and Dikkatwar, 2021).

**References**

Ahmed, I., Jeon, G. and Piccialli, F. (2022) ‘From Artificial Intelligence to Explainable Artificial Intelligence in Industry 4.0: A Survey on What, How, and Where’, IEEE Transactions on Industrial Informatics, 18(8): 5031–5042. DOI: https://doi.org/10.1109/TII.2022.3146552.

Herkert, J., Borenstein, J. and Miller, K. (2020) ‘The Boeing 737 MAX: Lessons for Engineering Ethics’, Science and Engineering Ethics, 26(6): 2957–2974. DOI: https://doi.org/10.1007/s11948-020-00252-y.

Laeequddin, M. and Dikkatwar, R. (2021) Boeing 737 Max-8: Design Choices and Their Consequences. 1 Oliver’s Yard, 55 City Road, London  EC1Y 1SP  United Kingdom: NeilsonJournals Publishing. DOI: https://doi.org/10.4135/9781529610925.

Vanderlinde, J., Robinson, K. and Mashford, B. (2022) ‘The challenges for artificial intelligence and systems engineering’, Australian Journal of Multi-Disciplinary Engineering, 18(1): 47–53. DOI: https://doi.org/10.1080/14488388.2022.2044607.